from scrapy.spider import Spider
from scrapy.http import FormRequest, Request
#import urllib2
#urllib2.install_opener(urllib2.build_opener(urllib2.HTTPCookieProcessor()))

class BookstoreSpider(Spider):
    name = "bookstore"
    allowed_domains = ["www.books.com.tw"]
    start_urls = ('http://www.student.tw/index.php',)


    def parse(self, response):
        for i, url in enumerate(self.start_urls):
            yield FormRequest(url, meta = {'cookiejar': i},
                                #formdata = self.formdata,
                                #headers = self.headers,
                                callback = self.login)#jump to login page


    def login(self):
        return [FormRequest.from_response(response,
                    formdata={	'username': 'exilespacer',
				'password': 'xx251227',
				'chk_password':'',
				'url':'http://www.books.com.tw/',
				'flag':'login',
				'sso_flag':0,
				'page1_login':'N',
			      },
		    meta = {'cookiejar':response.meta['cookiejar']},
                    callback=self.after_login)]




    def after_login(self, response):
        # check login succeed before going on
 	print(response.body)


